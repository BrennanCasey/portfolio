{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining some global variables for use in all of my functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global businessName\n",
    "global businessType\n",
    "global phoneNumber\n",
    "global address\n",
    "global driver\n",
    "\n",
    "global GOT_Data\n",
    "GOT_Data = pd.DataFrame(data={\"Business Name\":[], \"Business Types\": [],\"Phone Number\": [],\"Address\":[], \"Latitude\":[], \"Longitude\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for navigating through pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def openWindow(URL):\n",
    "    driver.execute_script(\"window.open(\"+URL+\");\")\n",
    "\n",
    "\n",
    "def closeWindow():\n",
    "    driver.execute_script(\"window.close();\") #might have to just make a second driver - xtraDriver and use xtraDriver.get\n",
    "\n",
    "def nextPage(): #finds the html object for the next button at the bottom of the page and clicks it\n",
    "    pageBlock = driver.find_element_by_class_name(\"pagination-block\")\n",
    "    results = pageBlock.find_elements_by_class_name(\"arrange_unit\")\n",
    "    results[-1].click() \n",
    "\n",
    "\n",
    "def isLastPage():\n",
    "    pageBlock = driver.find_element_by_css_selector(\"div[class='search-pagination']\")\n",
    "    pageNumberText = pageBlock.find_element_by_class_name(\"page-of-pages\").text\n",
    "    pageNumberText = pageNumberText[5:]\n",
    "    pageNumberText = pageNumberText.split(\" of \")\n",
    "    currentPage  = pageNumberText[0]\n",
    "    lastPage = pageNumberText[1]\n",
    "    if currentPage == lastPage:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def getInnerPageDetails():\n",
    "    \n",
    "    stars = driver.find_elements_by_class_name(\"i-stars\").get_attribute(\"title\")\n",
    "    stars = stars.split(\" \")\n",
    "    stars = stars[0]\n",
    "    \n",
    "    reviewCount = driver.find_elements_by_class_name(\"review-count\").text\n",
    "    reviewCount = reviewCount.split(\" \")\n",
    "    reviewCount = reviewCount[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrapeInnerPage(WebElement):\n",
    "    #Get URL from element from \n",
    "    URL = WebElement.find_element_by_class_name(\"biz-name\").get_attribute(\"href\")\n",
    "    #open WebElement in a new tab\n",
    "    openWindow(URL)\n",
    "\n",
    "    #BusinessName √\n",
    "    #Rating √\n",
    "    #Number_of_Reviews √\n",
    "    #Address √\n",
    "    #Coordinates √\n",
    "\n",
    "#scrape the data from the page\n",
    "def scrapePage():\n",
    "    results = []\n",
    "    results = driver.find_elements_by_css_selector(\"li[class='regular-search-result']\")\n",
    "    for result in results:\n",
    "        \n",
    "        businessTypeList = []\n",
    "        businessTypeObj = result.find_element_by_css_selector(\"span[class='category-str-list']\")\n",
    "        businessTypes = businessTypeObj.find_elements_by_tag_name(\"a\")\n",
    "        for each in businessTypes:\n",
    "            businessTypeList.append(each.text)\n",
    "        businessType.append(tuple(businessTypeList)) #some businesses have multiple biz types\n",
    "        nameGroup = result.find_element_by_class_name(\"biz-name\")\n",
    "        businessName.append(nameGroup.find_element_by_tag_name(\"span\").text)\n",
    "        latitude.append()\n",
    "        try:\n",
    "            phoneNumber.append(result.find_element_by_css_selector(\"span[class='biz-phone']\").text)\n",
    "        except:\n",
    "            phoneNumber.append(\"N/A\") # not every business has their phone number listed\n",
    "            print(\"No Phone Number\")\n",
    "        try:\n",
    "            justAddress = result.find_element_by_tag_name(\"address\").text\n",
    "            #append address to the name of the city so we have a full address of the business for later\n",
    "            address.append(justAddress + \", \" + result.find_element_by_css_selector(\"span[class='biz-city']\").text)\n",
    "        except:\n",
    "            try:\n",
    "                print('neighborhood') #if there is no neighborhood its probably a food truck and we can skip this data\n",
    "                justAddress = result.find_element_by_tag_name(\"address\").text\n",
    "                address.append(justAddress + \", \" + result.find_element_by_css_selector(\"span[class='neighborhood-str-list']\").text)\n",
    "            except:\n",
    "                address.append(\"N/A\")\n",
    "                print(\"Error: Possible Food Truck\")\n",
    "        \n",
    "\n",
    "def getCoordinates(URL_String): #gets coordinates from yelp page\n",
    "    #Takes URL_String and splices it in order to get the coordinates.\n",
    "    listOfURLParts = URL_String.split(\"&\")\n",
    "    for each in listOfURLParts:\n",
    "        if \"center\" in each:\n",
    "            coordinateString = each #center=40.711898%2C-74.017490\n",
    "    coordinateString = coordinateString.replace(\"center=\",\"\") #40.711898%2C-74.017490\n",
    "    geoList = coordinateString.split(\"%2C\")\n",
    "    geoPoint = {lat: geoList[0], long: geoList[1]}\n",
    "    return geoPoint\n",
    "        \n",
    "def scrapeCity(location):\n",
    "    #needs to take into account food trucks which have a distinct html object format\n",
    "    \n",
    "    businessName = []\n",
    "    phoneNumber = []\n",
    "    address = []\n",
    "    businessType = []\n",
    "    \n",
    "    script = \"arguments[0].setAttribute('value', '\"+location+\"' )\"\n",
    "\n",
    "    #find location text box\n",
    "    try:\n",
    "        searchBar = driver.find_element_by_xpath(\"//input[@id='search_location']\")\n",
    "    except:\n",
    "        searchBar = driver.find_element_by_xpath(\"//input[@id='dropperText_Mast']\")\n",
    "\n",
    "    locationTextBox = driver.find_element_by_xpath(\"//input[@name='find_loc']\")\n",
    "    #changes location to desired location\n",
    "    driver.execute_script(script, locationTextBox)\n",
    "    searchBar.send_keys(Keys.ENTER)\n",
    "    print(\"Attempting to Scrape\")\n",
    "    \n",
    "    n = 1\n",
    "    \n",
    "    while (isLastPage() is False): #runs until we are on the last page of yelp search results for that U.S. city\n",
    "        print(n) #just to see how long it takes to scrape one page\n",
    "        scrapePage()\n",
    "        nextPage()\n",
    "        n+=1\n",
    "    \n",
    "    #export data- each page adds to a larger subset of the dataframe- this way I dont lose all my data if some new html comes out of nowhere\n",
    "    df = pd.DataFrame(data={\"Business Name\":businessName, \"Business Types\": businessType,\"Phone Number\": phoneNumber,\"Address\":address})\n",
    "    addToDataFrame(df)\n",
    "    \n",
    "\n",
    "def scrapeYelpFromCityList(textFile): #loops each location and scrapes the pages around it\n",
    "    textFile = open(textFile,\"r\")\n",
    "    for line in textFile.readlines():\n",
    "        location = line.replace(\"\\n\",\"\")\n",
    "        print(location)\n",
    "        scrapeCity(location)\n",
    "        GOT_Data.to_csv(str(location)+'.csv')\n",
    "        GOT_Data = pd.DataFrame(data={\"Business Name\":[], \"Business Types\": [],\"Phone Number\": [],\"Address\":[]})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addToDataFrame(df): \n",
    "    GOT_Data = pd.concat([GOT_Data,df]).drop_duplicates().reset_index(drop=True) #drop duplicates because searching cities close by return the same businesses\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Run Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='/chromedriver')\n",
    "driver.get(\"https://www.yelp.com/search?find_desc=&find_loc=Hoboken%2C+NJ&ns=1\") #starting point for easy searching on yelp\n",
    "\n",
    "scrapeYelpFromCityList(\"USCities.txt\") #USCities.txt is a list created for all USCities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
